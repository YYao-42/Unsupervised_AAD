{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e82ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import utils_stream\n",
    "import utils_prob\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad94eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_per_subj(eeg_folder, feats_path_folder, fsStim, bads, trial_len=60):\n",
    "    eeg_files_all = [file for file in os.listdir(eeg_folder) if file.endswith('.set')]\n",
    "    files = [file for file in eeg_files_all if len(file.split('_')) == 3]\n",
    "    files.sort()\n",
    "    eeg_list = []\n",
    "    feats_list = []\n",
    "    label_list = []\n",
    "    for file in files:\n",
    "        eeg_downsampled, eog_downsampled, fs = utils.get_eeg_eog(eeg_folder + file, fsStim, bads, expdim=False)\n",
    "        eeg_reg = utils.regress_out(eeg_downsampled.T, eog_downsampled.T)\n",
    "        len_video = eeg_reg.shape[0]\n",
    "        name = file[:-4]\n",
    "        id_att = name.split('_')[-1]\n",
    "        ids = list(set(name.split('_')))\n",
    "        f1 = utils.get_features(feats_path_folder, ids[0], len_video, offset=122*fs, smooth=True)\n",
    "        f2 = utils.get_features(feats_path_folder, ids[1], len_video, offset=122*fs, smooth=True)\n",
    "        feats = np.stack((f1[:,8], f2[:,8]), axis=1)\n",
    "        label = 1 if id_att == ids[0] else 2\n",
    "\n",
    "        # eeg_trials = utils.into_trials(eeg_reg, fs, t=trial_len)\n",
    "        # feats_trials = utils.into_trials(feats, fs, t=trial_len)\n",
    "        # label_trials = [label] * len(eeg_trials)\n",
    "\n",
    "        # eeg_list += eeg_trials\n",
    "        # feats_list += feats_trials\n",
    "        # label_list += label_trials\n",
    "\n",
    "        eeg_list.append(eeg_reg)\n",
    "        feats_list.append(feats)\n",
    "        label_list.append(label)\n",
    "\n",
    "    return eeg_list, feats_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6e0ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['Pilot_1', 'Pilot_2', 'Pilot_4', 'Pilot_5', 'Pilot_6', 'Pilot_7', 'Pilot_8', 'Pilot_9', 'Pilot_10', 'Pilot_11', 'Pilot_12', 'Pilot_13', 'Pilot_14', 'Pilot_15', 'Pilot_17', 'Pilot_18', 'Pilot_19', 'Pilot_20', 'Pilot_21']\n",
    "# bads = [['A30', 'B25'], ['B25'], ['B25'], [], ['A31', 'B31'], ['B25'], ['A30', 'B25'], ['A30', 'B25'], ['B25'], ['B25', 'B26'], ['A30', 'B25'], ['B31'], ['B25', 'A23'], ['A30', 'B25'], ['B25'], ['B25'], ['A30', 'B25'], ['A30', 'B25'], ['B25']] \n",
    "# eeg_dict = {}\n",
    "# feats_dict = {}\n",
    "# labels_dict = {}\n",
    "# for subject, bad in zip(subjects, bads):\n",
    "#     eeg_folder = f\"../../Experiments/data/Two_Obj/Overlay/{subject}/\"\n",
    "#     feats_path_folder = '../Feat_Multi/features/'\n",
    "#     fsStim = 30\n",
    "#     eeg_trials, feats_trials, label_trials = data_per_subj(eeg_folder, feats_path_folder, fsStim, bad)\n",
    "#     eeg_dict[subject] = eeg_trials\n",
    "#     feats_dict[subject] = feats_trials\n",
    "#     labels_dict[subject] = label_trials\n",
    "\n",
    "# data_path = 'data/'\n",
    "# if not os.path.exists(data_path):\n",
    "#     os.makedirs(data_path)\n",
    "\n",
    "# with open(data_path + 'eeg_video.pkl', 'wb') as f:\n",
    "#     pickle.dump(eeg_dict, f)\n",
    "# with open(data_path + 'feats_video.pkl', 'wb') as f:\n",
    "#     pickle.dump(feats_dict, f)\n",
    "# with open(data_path + 'labels_video.pkl', 'wb') as f:\n",
    "#     pickle.dump(labels_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open('data/eeg_video.pkl', 'rb') as f:\n",
    "    eeg_dict = pickle.load(f)\n",
    "with open('data/feats_video.pkl', 'rb') as f:\n",
    "    feats_dict = pickle.load(f)\n",
    "with open('data/labels_video.pkl', 'rb') as f:\n",
    "    labels_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0811684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dimensions = 5\n",
    "fs = 30\n",
    "hparadata = [3, 1]\n",
    "hparafeats = [15, 0]\n",
    "evalpara = [3, 2]\n",
    "weightpara = [0.9, 0.9]\n",
    "SEED = 100\n",
    "PARATRANS = True\n",
    "nb_calibsessions = 1\n",
    "nb_disconnected = 0\n",
    "sub_trial_length = 60\n",
    "SHUFFLE = False\n",
    "UPDATE_STEP = 60 // sub_trial_length if sub_trial_length else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e53e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_trials_dict = {}\n",
    "feats_trials_dict = {}\n",
    "labels_trials_dict = {}\n",
    "for subject in eeg_dict.keys():\n",
    "    eeg_videos = eeg_dict[subject]\n",
    "    feats_videos = feats_dict[subject]\n",
    "    labels_videos = labels_dict[subject]\n",
    "    eeg_trials_all = []\n",
    "    feats_trials_all = []\n",
    "    labels_trials_all = []\n",
    "    for eeg, feats, label in zip(eeg_videos, feats_videos, labels_videos):\n",
    "        eeg_trials = utils.into_trials(eeg, fs, t=60)\n",
    "        feats_trials = utils.into_trials(feats, fs, t=60)\n",
    "        labels_trials = [label] * len(eeg_trials)\n",
    "        eeg_trials_all += eeg_trials\n",
    "        feats_trials_all += feats_trials\n",
    "        labels_trials_all += labels_trials\n",
    "    eeg_trials_dict[subject] = eeg_trials_all\n",
    "    feats_trials_dict[subject] = feats_trials_all\n",
    "    labels_trials_dict[subject] = labels_trials_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdb1df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subj = 'Pilot_17'\n",
    "# eeg_1 = eeg_trials_dict[Subj]\n",
    "# feats_1 = feats_trials_dict[Subj]\n",
    "# att_1, unatt_1 = utils_stream.select_att_unatt_feats(feats_1, labels_trials_dict[Subj])\n",
    "\n",
    "# import algo_ccazoo\n",
    "# views_list = [eeg_1, att_1]\n",
    "# params_hankel = [(3, 1), (15, 0)]\n",
    "# CCA = algo_ccazoo.CorrelationAnalysis(views_list, 'MCCA_LW', 30, params_hankel, CONTAIN_PARTIALS=False, n_components=3, leave_out=4, VALSET=False)\n",
    "# corr_att, corr_unatt, corr_mm, model_fold = CCA.vad_mm(trial_len=60, feat_unatt_list=unatt_1, MM=True)\n",
    "\n",
    "# utils.eval_compete(corr_att, corr_unatt, True, range_into_account=3, nb_comp_into_account=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0041853",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_subjects = ['Pilot_1', 'Pilot_5', 'Pilot_6', 'Pilot_10', 'Pilot_11', 'Pilot_12', 'Pilot_13', 'Pilot_14', 'Pilot_15', 'Pilot_17', 'Pilot_19', 'Pilot_20', 'Pilot_21']\n",
    "# selected_subjects = subjects\n",
    "est_subs = selected_subjects[:5]\n",
    "est_corr_att_sum, est_corr_unatt_sum = utils_prob.estimate_distribution_corr(eeg_trials_dict, feats_trials_dict, labels_trials_dict, est_subs, fs, hparadata, hparafeats, leave_out_persubj=4, trial_len=60, range_into_account=evalpara[0], nb_comp_into_account=evalpara[1])\n",
    "gmm_0, gmm_1 = utils_prob.fit_gmm(est_corr_att_sum, est_corr_unatt_sum, n_components_per_class=1)\n",
    "selected_subjects = selected_subjects[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b643bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_corr_att_unatt = np.stack([est_corr_att_sum, est_corr_unatt_sum], axis=1)\n",
    "est_corr_unatt_att = np.stack([est_corr_unatt_sum, est_corr_att_sum], axis=1)\n",
    "# 3. Create a grid to visualize the decision boundary\n",
    "x_min = min(est_corr_unatt_att[:,0].min(), est_corr_att_unatt[:,0].min()) - 0.1\n",
    "x_max = max(est_corr_unatt_att[:,0].max(), est_corr_att_unatt[:,0].max()) + 0.1\n",
    "y_min = min(est_corr_unatt_att[:,1].min(), est_corr_att_unatt[:,1].min()) - 0.1\n",
    "y_max = max(est_corr_unatt_att[:,1].max(), est_corr_att_unatt[:,1].max()) + 0.1\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))\n",
    "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "# 4. Predict probabilities for grid points\n",
    "grid_probs = utils_prob.predict_proba(grid_points, gmm_0, gmm_1)\n",
    "blue_probs = grid_probs[:, 1].reshape(xx.shape)\n",
    "\n",
    "# 5. Visualize the results\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot the data points\n",
    "plt.scatter(est_corr_unatt_att[:, 0], est_corr_unatt_att[:, 1], color='red', alpha=0.5, s=10, label='Class 0')\n",
    "plt.scatter(est_corr_att_unatt[:, 0], est_corr_att_unatt[:, 1], color='blue', alpha=0.5, s=10, label='Class 1')\n",
    "\n",
    "# Plot decision boundary (where probability = 0.5)\n",
    "plt.contour(xx, yy, blue_probs, levels=[0.5], colors='black', linestyles='-', linewidths=2)\n",
    "\n",
    "# Plot probability contours\n",
    "contour = plt.contourf(xx, yy, blue_probs, levels=np.linspace(0, 1, 11), \n",
    "                      alpha=0.3)\n",
    "plt.colorbar(contour, label='Probability of Class 1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subjects_dict = {}\n",
    "feats_subjects_dict = {}\n",
    "labels_subjects_dict = {}\n",
    "rng = np.random.RandomState(SEED)\n",
    "for subj in selected_subjects:\n",
    "    data_trials = eeg_trials_dict[subj]\n",
    "    if nb_disconnected > 0:\n",
    "        disconnected_channels = rng.choice(data_trials[0].shape[1], nb_disconnected, replace=False)\n",
    "        for i in range(len(data_trials)):\n",
    "            data_trials[i][:, disconnected_channels] = 0\n",
    "    data_trials = [utils_stream.process_data_per_view(d, hparadata[0], hparadata[1], NORMALIZE=True) for d in data_trials]\n",
    "    feats_trials = feats_trials_dict[subj]\n",
    "    feats_trials = [utils_stream.process_data_per_view(f, hparafeats[0], hparafeats[1], NORMALIZE=True) for f in feats_trials]\n",
    "    labels_trials = labels_trials_dict[subj]\n",
    "    if sub_trial_length is not None:\n",
    "        data_trials, feats_trials, labels_trials = utils_stream.further_split_and_shuffle(data_trials, feats_trials, labels_trials, sub_trial_length, fs, SHUFFLE=SHUFFLE, SEED=SEED)\n",
    "    data_subjects_dict[subj] = data_trials\n",
    "    feats_subjects_dict[subj] = feats_trials\n",
    "    labels_subjects_dict[subj] = labels_trials\n",
    "nb_trials = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = utils_stream.STREAM(data_subjects_dict, feats_subjects_dict, hparadata[0], hparafeats[0], latent_dimensions, SEED, evalpara, nb_trials, UPDATE_STEP)\n",
    "true_labels = np.concatenate([v[:nb_trials*UPDATE_STEP] for v in labels_subjects_dict.values()])\n",
    "\n",
    "pred_labels_dict = stream.fixed_supervised(labels_subjects_dict, selected_subjects[:nb_calibsessions], selected_subjects[nb_calibsessions:])\n",
    "pred_labels_fixed = np.concatenate([v for v in pred_labels_dict.values()])\n",
    "\n",
    "pred_labels_dict = stream.adaptive_supervised(labels_subjects_dict, weightpara, PARATRANS=PARATRANS)\n",
    "pred_labels_adapsup = np.concatenate([v for v in pred_labels_dict.values()])\n",
    "\n",
    "pred_labels_dict = stream.recursive(weightpara, PARATRANS=PARATRANS, SINGLEENC=True)\n",
    "pred_labels_single = np.concatenate([v for v in pred_labels_dict.values()])\n",
    "\n",
    "pred_labels_dict = stream.recursive(weightpara, PARATRANS=PARATRANS, SINGLEENC=False)\n",
    "pred_labels_two = np.concatenate([v for v in pred_labels_dict.values()])\n",
    "\n",
    "pred_labels_dict = stream.recursive_soft(weightpara, gmm_0, gmm_1, PARATRANS=PARATRANS)\n",
    "pred_labels_soft = np.concatenate([v for v in pred_labels_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc79c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"###########Fixed Supervised###########\")\n",
    "acc_non_calib_fixed, acc_fixed = utils_stream.calc_smooth_acc(pred_labels_fixed, true_labels, nb_trials, UPDATE_STEP, nearby=14, nb_calibsessions=nb_calibsessions)\n",
    "print(\"###########Adaptive Supervised###########\")\n",
    "acc_non_calib_adapsup, acc_adapsup = utils_stream.calc_smooth_acc(pred_labels_adapsup, true_labels, nb_trials, UPDATE_STEP, nearby=14, nb_calibsessions=nb_calibsessions)\n",
    "print(\"###########Single-Encoder###########\")\n",
    "acc_non_calib_single_enc, acc_single = utils_stream.calc_smooth_acc(pred_labels_single, true_labels, nb_trials, UPDATE_STEP, nearby=14, nb_calibsessions=nb_calibsessions)\n",
    "print(\"###########Two-Encoder###########\")\n",
    "acc_non_calib, acc_two = utils_stream.calc_smooth_acc(pred_labels_two, true_labels, nb_trials, UPDATE_STEP, nearby=14, nb_calibsessions=nb_calibsessions)\n",
    "print(\"###########Soft-Recursive###########\")\n",
    "acc_non_calib_soft, acc_soft = utils_stream.calc_smooth_acc(pred_labels_soft, true_labels, nb_trials, UPDATE_STEP, nearby=14, nb_calibsessions=nb_calibsessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb156df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(10, 3))\n",
    "x_axis = np.arange(len(true_labels))/UPDATE_STEP\n",
    "plt.plot(x_axis, acc_two, label='Two-Enc', color='orange')\n",
    "plt.plot(x_axis, acc_single, label='Single-Enc', color='blue')\n",
    "plt.plot(x_axis, acc_adapsup, label='Adaptive Supervised', color='red')\n",
    "plt.plot(x_axis[nb_calibsessions*nb_trials*UPDATE_STEP:], acc_fixed, label='Fixed Supervised', color='green')\n",
    "plt.plot(x_axis, acc_soft, label='Soft-Recursive', color='purple')\n",
    "# mark recur_acc_se and recur_acc_te in title\n",
    "plt.title(f\"FixSup: {acc_non_calib_fixed:.2f}, Single-Enc: {acc_non_calib_single_enc:.2f}, Two-Enc: {acc_non_calib:.2f}, Soft: {acc_non_calib_soft:.2f}, AdaSup: {acc_non_calib_adapsup:.2f}\")\n",
    "plt.xlabel('time (min)')\n",
    "plt.ylabel('accuracy')\n",
    "for i in range(nb_calibsessions, len(selected_subjects)):\n",
    "    plt.axvline(x=i*nb_trials, color='grey', linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f1f54b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccazoo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
