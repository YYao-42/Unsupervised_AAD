{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e82ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import utils_unsup\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import scipy\n",
    "import copy\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_att_unatt_feats(feats_trials, label_trials):\n",
    "    nb_trials = len(feats_trials)\n",
    "    att_trials = []\n",
    "    unatt_trials = []\n",
    "    for i in range(nb_trials):\n",
    "        feats = feats_trials[i]\n",
    "        att = feats[:, label_trials[i]-1]\n",
    "        unatt = feats[:, 2-label_trials[i]]\n",
    "        att_trials.append(np.expand_dims(att, axis=1))\n",
    "        unatt_trials.append(np.expand_dims(unatt, axis=1))\n",
    "    return att_trials, unatt_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b891c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trial(views, nb_trials=2):\n",
    "    T = views[0].shape[0]\n",
    "    views_split = [[view[:T//nb_trials,...], view[T//nb_trials:,...]] for view in views]\n",
    "    return views_split\n",
    "\n",
    "def predict_labels(views, model, L_data, L_feats, evalpara, SPLIT=False):\n",
    "    data, att_unatt = views\n",
    "    if SPLIT:\n",
    "        dim_feats = att_unatt.shape[1]//2\n",
    "        att = att_unatt[:, :dim_feats]\n",
    "        unatt = att_unatt[:, dim_feats:]\n",
    "        model_single_enc = copy.deepcopy(model)\n",
    "        model_single_enc.weights_[1] = model.weights_[1][:L_feats, :]\n",
    "        data_pred_trials, att_pred_trials, unatt_pred_trials = split_trial([data, att, unatt])\n",
    "        corr_a = [model_single_enc.average_pairwise_correlations([d, f]) for d, f in zip(data_pred_trials, att_pred_trials)]\n",
    "        corr_sum_a = [utils_unsup.cal_corr_sum(corr, evalpara[0], evalpara[1]) for corr in corr_a]\n",
    "        corr_u = [model_single_enc.average_pairwise_correlations([d, f]) for d, f in zip(data_pred_trials, unatt_pred_trials)]\n",
    "        corr_sum_u = [utils_unsup.cal_corr_sum(corr, evalpara[0], evalpara[1]) for corr in corr_u]\n",
    "        label = [corr_sum_a[i] > corr_sum_u[i] for i in range(len(corr_sum_a))]\n",
    "        # data_pred_trials, att_unatt_trials = split_trial([data, att_unatt])\n",
    "        # influ_trials = [utils.get_influence_all_views([d, f], model.weights_, [L_data, L_feats], 'SDP', CROSSVIEW=True, NORMALIZATION=False)[1] for d, f in zip(data_pred_trials, att_unatt_trials)]\n",
    "        # label = [influ[0,0] > influ[1,0] for influ in influ_trials]\n",
    "    else:\n",
    "        # dim_feats = att_unatt.shape[1]//2\n",
    "        # att = att_unatt[:, :dim_feats]\n",
    "        # unatt = att_unatt[:, dim_feats:]\n",
    "        # model_single_enc = copy.deepcopy(model)\n",
    "        # model_single_enc.weights_[1] = model.weights_[1][:L_feats, :]\n",
    "        # corr_a = model_single_enc.average_pairwise_correlations([data, att])\n",
    "        # corr_sum_a = utils_unsup.cal_corr_sum(corr_a, evalpara[0], evalpara[1])\n",
    "        # corr_u = model_single_enc.average_pairwise_correlations([data, unatt])\n",
    "        # corr_sum_u = utils_unsup.cal_corr_sum(corr_u, evalpara[0], evalpara[1])\n",
    "        # label = corr_sum_a > corr_sum_u\n",
    "        # label = [corr_sum_a[i] > corr_sum_u[i] for i in range(len(corr_sum_a))]\n",
    "        influ = utils.get_influence_all_views([data, att_unatt], model.weights_, [L_data, L_feats], 'SDP', CROSSVIEW=True, NORMALIZATION=False)[1]\n",
    "        label = influ[0,0] > influ[1,0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a86d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_multi_sessions(data_conditions_dict, att_conditions_dict, unatt_conditions_dict, L_data, L_feats, latent_dimensions, weightpara, SEED, evalpara, PARATRANS=False, nb_trials=None):\n",
    "    model_init = None\n",
    "    pred_labels = []\n",
    "    for cond in ['CS-1', 'CS-2', 'TS-1', 'TS-2', 'TS-3', 'TS-4', 'FUS-1', 'FUS-2']:\n",
    "        segs_views = [[data, np.concatenate((att, unatt), axis=1)] for data, att, unatt in zip(data_conditions_dict[cond], att_conditions_dict[cond], unatt_conditions_dict[cond])]\n",
    "        if model_init is not None:\n",
    "            model = model_init\n",
    "            Rinit = Rinit\n",
    "            Dinit = Dinit\n",
    "        else:\n",
    "            model = utils_unsup.train_cca_model_adaptive(segs_views[0], None, None, latent_dimensions=latent_dimensions, weightpara=weightpara, RANDMODEL=True, SEED=SEED)\n",
    "            Rinit = None \n",
    "            Dinit = None\n",
    "        pred_labels.append(predict_labels(segs_views[0], model, L_data, L_feats, evalpara, SPLIT=True))\n",
    "        nb_trials = len(segs_views) if nb_trials is None else nb_trials\n",
    "        for i in range(nb_trials):\n",
    "            # update the model\n",
    "            seg_to_pred = segs_views[i]\n",
    "            label = predict_labels(seg_to_pred, model, L_data, L_feats, evalpara, SPLIT=False)\n",
    "            if label:\n",
    "                seg_predicted = seg_to_pred\n",
    "            else:\n",
    "                seg_predicted = [seg_to_pred[0], np.concatenate([seg_to_pred[1][:, L_feats:], seg_to_pred[1][:, :L_feats]], axis=1)]\n",
    "            model = utils_unsup.train_cca_model_adaptive(seg_predicted, Rinit, Dinit, latent_dimensions=latent_dimensions, weightpara=weightpara, RANDMODEL=False, SEED=SEED)\n",
    "            Rinit = model.Rxx \n",
    "            Dinit = model.Dxx\n",
    "            if i < nb_trials - 1:\n",
    "                # predict labels of the next trial\n",
    "                pred_labels.append(predict_labels(segs_views[i+1], model, L_data, L_feats, evalpara, SPLIT=True))\n",
    "        if PARATRANS:\n",
    "            model_init = model\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_multi_sessions(data_conditions_dict, att_conditions_dict, unatt_conditions_dict, L_data, L_feats, latent_dimensions, pool_size, SEED, evalpara, PARATRANS=False, nb_trials=None):\n",
    "    model_init = None\n",
    "    pred_labels = []\n",
    "    for cond in ['CS-1', 'CS-2', 'TS-1', 'TS-2', 'TS-3', 'TS-4', 'FUS-1', 'FUS-2']:\n",
    "        segs_views = [[data, np.concatenate((att, unatt), axis=1)] for data, att, unatt in zip(data_conditions_dict[cond], att_conditions_dict[cond], unatt_conditions_dict[cond])]\n",
    "        dim_hankel = [view.shape[1] for view in segs_views[0]]\n",
    "        cov_tensor_precomputed = utils_unsup.get_cov_tensor(segs_views, regularization='lwcov')\n",
    "        if model_init is not None:\n",
    "            model = model_init\n",
    "            pool_init = pool_init\n",
    "        else:\n",
    "            pool_init = np.zeros((cov_tensor_precomputed.shape[0], cov_tensor_precomputed.shape[1], pool_size))\n",
    "            pool_init[:,:,-1] = cov_tensor_precomputed[:,:,0]\n",
    "            model = utils_unsup.train_cca_model_pool(pool_init, dim_hankel[0], latent_dimensions=latent_dimensions, RANDMODEL=True, SEED=SEED)\n",
    "        pred_labels.append(predict_labels(segs_views[0], model, L_data, L_feats, evalpara, SPLIT=True))\n",
    "        nb_trials = len(segs_views) if nb_trials is None else nb_trials\n",
    "        for i in range(nb_trials):\n",
    "            # Move to the next segment, predict the labels, and update the pool\n",
    "            pool_tensor = np.zeros_like(pool_init)\n",
    "            pool_tensor[:, :, 1:] = pool_init[:, :, :-1]\n",
    "            pool_tensor[:, :, 0] = cov_tensor_precomputed[:, :, i]\n",
    "            pool_init = pool_tensor\n",
    "            pool_tensor, _ = utils_unsup.update_pool(pool_tensor, dim_hankel, model.weights_, evalpara)\n",
    "            model = utils_unsup.train_cca_model_pool(pool_tensor, dim_hankel[0], latent_dimensions=latent_dimensions, RANDMODEL=False, SEED=SEED)\n",
    "            if i < nb_trials - 1:\n",
    "                # predict labels of the next trial\n",
    "                pred_labels.append(predict_labels(segs_views[i+1], model, L_data, L_feats, evalpara, SPLIT=True))\n",
    "        if PARATRANS:\n",
    "            model_init = model\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab57979",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dimensions = 5\n",
    "fs = 20\n",
    "hparadata = [9, 8]\n",
    "hparafeats = [1, 0]\n",
    "evalpara = [1, 1]\n",
    "weightpara = [0.9, 0.9]\n",
    "pool_size = 19\n",
    "SEED = 2\n",
    "PARATRANS = True\n",
    "nb_trials = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b483ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read .mat files\n",
    "Subj_ID = 1\n",
    "data_path = '../../Experiments/data/Zink/dataSubjectOfficial{}.mat'.format(Subj_ID)\n",
    "data = scipy.io.loadmat(data_path, squeeze_me=True)\n",
    "conditions = data['condition']\n",
    "unique_conditions = np.unique(conditions)\n",
    "data_conditions_dict = {}\n",
    "att_conditions_dict = {}\n",
    "unatt_conditions_dict = {}\n",
    "for cond in unique_conditions:\n",
    "    data_trials = data['eegTrials'][conditions == cond]\n",
    "    data_conditions_dict[cond] = [d for d in data_trials]\n",
    "    data_conditions_dict[cond] = [utils_unsup.process_data_per_view(d, hparadata[0], hparadata[1], NORMALIZE=True) for d in data_conditions_dict[cond]]\n",
    "    att_conditions_dict[cond], unatt_conditions_dict[cond] = select_att_unatt_feats(data['audioTrials'][conditions == cond], data['attSpeaker'][conditions == cond])\n",
    "    att_conditions_dict[cond] = [utils_unsup.process_data_per_view(d, hparafeats[0], hparafeats[1], NORMALIZE=True) for d in att_conditions_dict[cond]]\n",
    "    unatt_conditions_dict[cond] = [utils_unsup.process_data_per_view(d, hparafeats[0], hparafeats[1], NORMALIZE=True) for d in unatt_conditions_dict[cond]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e5b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = recursive_multi_sessions(data_conditions_dict, att_conditions_dict, unatt_conditions_dict, hparadata[0], hparafeats[0], latent_dimensions, weightpara, SEED, evalpara, PARATRANS=PARATRANS, nb_trials=nb_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbe4b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_non_calib = pred_labels[2*nb_trials:]\n",
    "labels_non_calib = [item for sublist in labels_non_calib for item in sublist]\n",
    "np.sum(labels_non_calib)/len(labels_non_calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a21394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all = [item for sublist in pred_labels for item in sublist]\n",
    "acc_recur = []\n",
    "for i in range(len(labels_all)):\n",
    "    idx_range = (max(0, i-14), min(len(labels_all), i+14))\n",
    "    acc_recur.append(np.sum(labels_all[idx_range[0]:idx_range[1]])/len(labels_all[idx_range[0]:idx_range[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2e7348",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = sliding_multi_sessions(data_conditions_dict, att_conditions_dict, unatt_conditions_dict, hparadata[0], hparafeats[0], latent_dimensions, pool_size, SEED, evalpara, PARATRANS=PARATRANS, nb_trials=nb_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_non_calib = pred_labels[2*nb_trials:]\n",
    "labels_non_calib = [item for sublist in labels_non_calib for item in sublist]\n",
    "np.sum(labels_non_calib)/len(labels_non_calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b71ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all = [item for sublist in pred_labels for item in sublist]\n",
    "acc_slid = []\n",
    "for i in range(len(labels_all)):\n",
    "    idx_range = (max(0, i-14), min(len(labels_all), i+14))\n",
    "    acc_slid.append(np.sum(labels_all[idx_range[0]:idx_range[1]])/len(labels_all[idx_range[0]:idx_range[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe09c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "x_axis = np.arange(len(acc_recur))/2\n",
    "plt.plot(x_axis, acc_recur, label='Recursive', color='blue')\n",
    "plt.plot(x_axis, acc_slid, label='Sliding Window', color='orange')\n",
    "for i in range(1, 9):\n",
    "    plt.axvline(x=i*nb_trials, color='grey', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6f5c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccazoo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
